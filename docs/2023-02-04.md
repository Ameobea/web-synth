# 2023-02-04

MAIN GOAL: Plan out tasks and goals for today's work

## Moving MIDI event scheduling to the audio thread

We want to avoid the random delay that comes from round-tripping MIDI events from the audio thread -> UI thread -> audio thread when dealing with the scheduler.

In order to do this, we will add an opt-in ability for scheduling to send MIDI events to mailboxes on the audio thread directly.  Right now, I only want to do this with the synth designer.  I looked into it yesterday, and I don't think this will be too difficult for the synth designer tbh.  The gate function for the synth designer basically just calls two methods that send messages to the audio thread as it is.

There are some hurdles we'll have to get past in order to make this work.  One worry I have is that the scheduler node will not run before the other nodes, which will cause up to a frame of delay during scheduling.  This probably isn't even worth thinking about right now, though.

### PolySynth context

Something I forgot about.  We use that polysynth context to handle voice scheduling.  We will need to move that to the audio thread as well in order to make this work, since the current polysynth state lives in the UI thread.

We'll need to update that module to remove the wasm-bindgen stuff since that doesn't work in AWPs, and then make some changes to get it loaded in the audio thread.

## Scheduling/Mailbox Design

All global state is shared between different `AudioWorkletProcessor`s on the audio thread.  So, we should be able to just set in a global there that holds mailboxes for all opted-in nodes and write/read from those directly.

I'd like to avoid allocation for this, so I think that doing some kind of ring buffer structure will be good.  We can write MIDI events into the buffer along with what samples they will occur on, and then when they're consumed we just increment the index or whatever.

## Indicating Opt-In Intent

Probably want to do it at the MIDI node level.  We can set some kind of flag on the MIDI node that says "yeah we'll consume these events on the audio thread directly" and in that case, the sender can choose to send them that way instead.

## Follow-Up Work

I want to update MIDI editor scheduling to avoid the delay when starting.  If global playback is started and the MIDI editor has a note scheduled at beat 0, it won't be picked up by envelope generators etc. until like beat 0.05.  Want to eliminate that delay somehow if possible.  Probably will have to do scheduling ahead of time before the global beat counter is started, or register a callback that fires before it actually starts or something.

----

OK, so we've made some progress here, but I'm stuck on the part where we actually move stuff over.

MIDI events -> Synth Designer

Events are either interactive or scheduled.  Interactive events will always originate from the UI thread.  What we have to figure out is if we want to allow events to come from both UI thread and audio thread, or to force all events to come from audio thread when that mode is opted-in.

I think we're going to go with all events getting scheduled on the audio thread if that mode is opted-in.  If we get a dynamic MIDI event coming in from somewhere going to a node that expects audio thread scheduling, we will write it into the ring buffer via message posted to the audio thread.

So, to port over the FM synth to this new scheduling method, we're not going to expose frequency params at all for FM synth.  We'll manage our own frequencies per-voice all on the audio thread, based on the events received from the mailbox.

----

Current Status:

We've implemented the mailbox and implemented the system for writing interactive MIDI events from the UI thread into the mailbox on the audio thread.

We've made the required changes to the FM synth to un-expose the frequency params and consume MIDI events from the mailbox directly.  We've moved the polysynth context from the UI thread onto the audio thread inside the FM synth itself.

We've run into a bit of a snag with the FM synth filter envelope.  It's polyphonic, so it requires a voice index when being gated.  However, the voice ix currently only lives within the FM synth; we're unable to get a voice ix when consuming MIDI events from the mailbox.  To resolve this, we will have to move the FM synth filter envelope generator into the FM synth itself.  This will simplify stuff with the synth designer and allow us to get the proper voice indices to make it work.  Currently, we're using round-trips to the UI thread which adds latency onto the FM synth filter envelope gating/ungating.  However, it's kinda broken as it is anyway so I don't think it matters too much rn.

Everything seems to be working, but we're not actually making use of audio thread scheduling rn.  The scheduling is still doing a round-trip to the UI thread which is writing back to the audio thread to write to the mailbox.

----

So yeah, we need to figure out the event scheduler integration for writing into mailboxes.  We need to be able to tell it "write this MIDI event into this mailbox ID at this beat".
