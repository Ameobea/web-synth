# 2021-04-25

MAIN GOAL: Plan out what kind of features + functionality we want/need for the [[sample-editor]], sample playback, and other sample-related modules.

Working with samples is a vital part of music production, and I've reached a stage of the project where I find that I have a need to manipulate, record, and work with samples dynamically with the tool itself.  Currently, the only thing that exists is the sample recorder that's glued on top of the granular synth.  That's obviously not the right place for that to be, and we should have a dedicated sample recorder node/component - possibly one that's combined with a top level [[sample-editor]] component.

So, what exactly is the sample recorder going to consist of?  What do we want to do?

Well, one thing that we definitely want to be able to do is cut up and combine samples in an audacity-like fashion.  I want to be able to reverse samples in-place, place many samples in order to produce rhythms, place one-shot samples, etc.  So more and more the core of this functionality is looking like a single track of Audacity.  Of course, there are many pieces of this that will need to be created in order to make it work.  Happily, I think that this is something taht can sit on top of the notebox backend that we built before; so many of its features and functionalities match directly.

Before we go on, I want to make extra sure that this is actually required.  I'm almost sure that it is, but let's list the places that I'm almost sure that this will be needed right now:

 - track compositor, where we will have sample tracks that can be edited and composited like MIDI tracks
 - standalone VC for sample recording/import/export.  I think that this is something that will be important; the actual "sample editor" VC.  It will basically be the same UI as the single sample track editor and have the same features, but we can have a toolbar there with import/export functionality, tight integration into the [[sample-library]], and stuff like that.

Yeah I think that's the gist of it.  It's become quite clear that the single track sample editor is the core of what we want to build.  Let's flesh that idea out further.

There will be multiple samples which will be the "notes" for the line.  Each note has a sample that is associated with it and some set of modifiers.  I like the idea of having some source sample and a list of transformations applied to it which yield the output sample which is actually played.  We can cache all of the layers and save a rendered version of the output for efficiency, but it makes sense that we need some kind of source audio data to fall back to which contains the actual data.

There will need to be an AWP which handles actually playing back the line of samples.  That will be OK; playing back samples is pretty easy you just read stuff out of a buffer.  There may be some annoying sample alignment kinds of things to deal with, but I think it won't be too big of a problem.  We will need to write the code for the various sample transformations, but we can handle that in a number of ways and there is no real-time need for that so that's cool too.

We might end up setting up some kind of class inheritance for things like looping-- actually probably not.  We're handling that pretty fundamentally differently.  I like the idea of just building everything from scratch for the sample editor; it's very different from the MIDI editor in more ways than one.  If we want to re-use zooming/panning/etc. functionality, we can do so by pulling out helper functions I think.

I think it is a good idea to plan for having many of these sample lines together in the same view and controllable as a group, just like Audacity.  I don't have an exact vision for how that will work or what the exact requirements for that will be, but making view stuff externally controllable is a good idea probably.  I don't think we will need to do a ton to facilitate that, though.

There is a need for waveform renderer.  We already have a primitive version of that built, and we probably want to upgrade it.  We can do interpolation and stuff.  We can add caching if we need to.  This will be a function-like thing rather than any kind of module, similar to the note lines backend.  We call into it to get the data we need, and then we render it from within PIXI.

I think the idea of having arrays of transformations applied to source samples is a neat one.  I've been trying to think of ways in which it won't meet the needs of what we want to do, but I can't really think of any.  There might be issues if samples are deleted or note available.  An alternative I can think of is saving transformed samples as data rather than transforms on source samples.  This removes the dependency on the source sample, but it adds the requirement of saving the derived samples data with the sample editor somehow.  We can use IndexedDB for that, persist them to server once user accounts are up and running, no problem.  I'm thinking that this is a better idea; the idea of having stacked transformations is cool and nice and feels quite smart, but I don't think there will really be any benefit to it.  We can have a registry of internal samples that is associated with the sample manager isntance.  The backing store doesn't matter too much, but basically we have a set of samples that we have created and care about and whenever we create a transformed sample we create a new entry in that registry and use that.  It's simpler and more flexible than the original, imo.

SO - going into thinking about actually buliding this.  What does an MVP look like?

We need the actual sample line UI, need to be able to -- let me make a list:

 - Basic sample line UI with scrolling, zooming, waveform rendering.  Need to be able to drag in samples, move them around, copy/paste.
 - AWP to serve as the backend for the sample editor.  We will need to communicate UI updates to it when the UI is updated, handle de/serialization, handle updates, and render audio live based on current beat.  There are probably pieces here that I'm forgetting as well; this might end up being somewhat involved due to the surface between the frontend and the AWP but we'll see.  I briefly considered merging this with the [[granular-synthesizer]], but decided against it.  I think this should be a greenfield implementation solely focused on playing back samples with no special handling or anything like that.  Max efficiency, max efficiency, etc.
 - Sample transformations.  I want to be able to do things like pitch samples up/down, reverse samples, cut up samples, etc.
 - Sample recorder UI.  It will embed a single sample line and expose VCs for inputs and outputs (passthrough) with a toolbar to control.  Should be versatile to support both capturing + editing actual samples as well as a sort of export node for full songs.  We can prioritize this after the main sample editor piece since it's going to embed almost all of it.

And... that's as far as I've thought so far.  I think that this is actually a pretty good roadmap and that having this will greatly improve the capabilities of the platform as a whole.  I'm pretty convinced that dealing with samples is very important; dealing with raw audio data like this is something that's universally necessary and I'm looking forward to having support for that in the application.

Tomorrow, we build.  Right now, we sleep.

[//begin]: # "Autogenerated link references for markdown compatibility"
[sample-library]: sample-library "sample-library"
[//end]: # "Autogenerated link references"
